{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:11.844170Z",
     "start_time": "2022-02-01T13:18:09.916364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch Version : 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import uwb_dataset\n",
    "\n",
    "\n",
    "print(\"Pytorch Version :\", torch.__version__)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:11.859706Z",
     "start_time": "2022-02-01T13:18:11.845170Z"
    }
   },
   "outputs": [],
   "source": [
    "retrain = False\n",
    "path = os.getcwd()\n",
    "dir_ = 'model'\n",
    "checkpoint_name = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:11.875710Z",
     "start_time": "2022-02-01T13:18:11.861706Z"
    }
   },
   "outputs": [],
   "source": [
    "if retrain:\n",
    "    checkpoint_path = os.path.join(path, dir_ , checkpoint_name)\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:11.891713Z",
     "start_time": "2022-02-01T13:18:11.876710Z"
    }
   },
   "outputs": [],
   "source": [
    "# random seed\n",
    "random_seed = 42\n",
    "\n",
    "num_epoch = 100\n",
    "batch_size = 64\n",
    "in_channels = 1\n",
    "num_classes = 2\n",
    "num_layers = 2\n",
    "fully_connected = 128\n",
    "\n",
    "lr = 0.001\n",
    "weight_decay = 0.0\n",
    "\n",
    "# Parameters\n",
    "view_train_iter = 100\n",
    "view_val_iter = 5\n",
    "save_point = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:11.907717Z",
     "start_time": "2022-02-01T13:18:11.892713Z"
    }
   },
   "outputs": [],
   "source": [
    "def torch_random_seed(on_seed=False, random_seed=1):\n",
    "    if on_seed:\n",
    "        torch.manual_seed(random_seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "        np.random.seed(random_seed)\n",
    "        random.seed(random_seed)\n",
    "        \n",
    "torch_random_seed(on_seed=True, random_seed=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:11.915572Z",
     "start_time": "2022-02-01T13:18:11.908717Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_clf_eval(y_true, y_pred, average='weighted'):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=average, warn_for=tuple())\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load UWB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:16.429914Z",
     "start_time": "2022-02-01T13:18:11.915572Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/uwb_dataset_part1.csv\n",
      "./dataset/uwb_dataset_part2.csv\n",
      "./dataset/uwb_dataset_part3.csv\n",
      "./dataset/uwb_dataset_part4.csv\n",
      "./dataset/uwb_dataset_part5.csv\n",
      "./dataset/uwb_dataset_part6.csv\n",
      "./dataset/uwb_dataset_part7.csv\n",
      "\n",
      "Columns : (1031,)\n",
      "Data : (42000, 1031)\n"
     ]
    }
   ],
   "source": [
    "columns, data = uwb_dataset.import_from_files()\n",
    "\n",
    "for item in data:\n",
    "\titem[15:] = item[15:]/float(item[2])\n",
    "\n",
    "print(\"\\nColumns :\", columns.shape, sep=\" \")\n",
    "print(\"Data :\", data.shape, sep=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View UWB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:16.445917Z",
     "start_time": "2022-02-01T13:18:16.431915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns : ['NLOS' 'RANGE' 'FP_IDX' ... 'CIR1013' 'CIR1014' 'CIR1015']\n",
      "Channel Inpulse Response Count : 1016\n"
     ]
    }
   ],
   "source": [
    "cir_n = len(columns[15:])\n",
    "\n",
    "print(\"Columns :\", columns, sep=\" \")\n",
    "print(\"Channel Inpulse Response Count :\", cir_n, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:16.701976Z",
     "start_time": "2022-02-01T13:18:16.446918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel 2 count : 42000\n",
      "Null/NaN Data Count :  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLOS</th>\n",
       "      <th>RANGE</th>\n",
       "      <th>FP_IDX</th>\n",
       "      <th>FP_AMP1</th>\n",
       "      <th>FP_AMP2</th>\n",
       "      <th>FP_AMP3</th>\n",
       "      <th>STDEV_NOISE</th>\n",
       "      <th>CIR_PWR</th>\n",
       "      <th>MAX_NOISE</th>\n",
       "      <th>RXPACC</th>\n",
       "      <th>...</th>\n",
       "      <th>CIR1006</th>\n",
       "      <th>CIR1007</th>\n",
       "      <th>CIR1008</th>\n",
       "      <th>CIR1009</th>\n",
       "      <th>CIR1010</th>\n",
       "      <th>CIR1011</th>\n",
       "      <th>CIR1012</th>\n",
       "      <th>CIR1013</th>\n",
       "      <th>CIR1014</th>\n",
       "      <th>CIR1015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.90</td>\n",
       "      <td>745.0</td>\n",
       "      <td>18712.0</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>11576.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>11855.0</td>\n",
       "      <td>967.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374497</td>\n",
       "      <td>0.614765</td>\n",
       "      <td>0.245638</td>\n",
       "      <td>0.212081</td>\n",
       "      <td>0.265772</td>\n",
       "      <td>0.116779</td>\n",
       "      <td>0.397315</td>\n",
       "      <td>0.677852</td>\n",
       "      <td>0.412081</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>749.0</td>\n",
       "      <td>11239.0</td>\n",
       "      <td>6313.0</td>\n",
       "      <td>4712.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>18968.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192256</td>\n",
       "      <td>0.445928</td>\n",
       "      <td>0.387183</td>\n",
       "      <td>0.304406</td>\n",
       "      <td>0.249666</td>\n",
       "      <td>0.284379</td>\n",
       "      <td>0.269693</td>\n",
       "      <td>0.118825</td>\n",
       "      <td>0.137517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.86</td>\n",
       "      <td>746.0</td>\n",
       "      <td>4355.0</td>\n",
       "      <td>5240.0</td>\n",
       "      <td>3478.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>14699.0</td>\n",
       "      <td>894.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042895</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300268</td>\n",
       "      <td>0.233244</td>\n",
       "      <td>0.166220</td>\n",
       "      <td>0.441019</td>\n",
       "      <td>0.277480</td>\n",
       "      <td>0.128686</td>\n",
       "      <td>0.292225</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1031 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NLOS  RANGE  FP_IDX  FP_AMP1  FP_AMP2  FP_AMP3  STDEV_NOISE  CIR_PWR  \\\n",
       "0   0.0   3.90   745.0  18712.0  10250.0  11576.0         64.0  11855.0   \n",
       "1   0.0   0.66   749.0  11239.0   6313.0   4712.0         64.0  18968.0   \n",
       "2   1.0   7.86   746.0   4355.0   5240.0   3478.0         60.0  14699.0   \n",
       "\n",
       "   MAX_NOISE  RXPACC  ...   CIR1006   CIR1007   CIR1008   CIR1009   CIR1010  \\\n",
       "0      967.0   611.0  ...  0.374497  0.614765  0.245638  0.212081  0.265772   \n",
       "1     1133.0   447.0  ...  0.192256  0.445928  0.387183  0.304406  0.249666   \n",
       "2      894.0   723.0  ...  0.042895  0.500000  0.300268  0.233244  0.166220   \n",
       "\n",
       "    CIR1011   CIR1012   CIR1013   CIR1014  CIR1015  \n",
       "0  0.116779  0.397315  0.677852  0.412081      0.0  \n",
       "1  0.284379  0.269693  0.118825  0.137517      0.0  \n",
       "2  0.441019  0.277480  0.128686  0.292225      0.0  \n",
       "\n",
       "[3 rows x 1031 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uwb = pd.DataFrame(data=data, columns=columns)\n",
    "print(\"Channel 2 count :\", df_uwb.query(\"CH == 2\")['CH'].count())\n",
    "print(\"Null/NaN Data Count : \", df_uwb.isna().sum().sum())\n",
    "df_uwb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:16.846008Z",
     "start_time": "2022-02-01T13:18:16.701976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line of Sight Count : 21000\n",
      "Non Line of Sight Count : 21000\n"
     ]
    }
   ],
   "source": [
    "los_count = df_uwb.query(\"NLOS == 0\")[\"NLOS\"].count()\n",
    "nlos_count = df_uwb.query(\"NLOS == 1\")[\"NLOS\"].count()\n",
    "\n",
    "print(\"Line of Sight Count :\", los_count)\n",
    "print(\"Non Line of Sight Count :\", nlos_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:16.926027Z",
     "start_time": "2022-02-01T13:18:16.847009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UWB DataFrame X for Trainndarray shape :  (42000, 1016)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIR0</th>\n",
       "      <th>CIR1</th>\n",
       "      <th>CIR2</th>\n",
       "      <th>CIR3</th>\n",
       "      <th>CIR4</th>\n",
       "      <th>CIR5</th>\n",
       "      <th>CIR6</th>\n",
       "      <th>CIR7</th>\n",
       "      <th>CIR8</th>\n",
       "      <th>CIR9</th>\n",
       "      <th>...</th>\n",
       "      <th>CIR1006</th>\n",
       "      <th>CIR1007</th>\n",
       "      <th>CIR1008</th>\n",
       "      <th>CIR1009</th>\n",
       "      <th>CIR1010</th>\n",
       "      <th>CIR1011</th>\n",
       "      <th>CIR1012</th>\n",
       "      <th>CIR1013</th>\n",
       "      <th>CIR1014</th>\n",
       "      <th>CIR1015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.173154</td>\n",
       "      <td>0.418792</td>\n",
       "      <td>0.444295</td>\n",
       "      <td>0.189262</td>\n",
       "      <td>0.214765</td>\n",
       "      <td>0.655034</td>\n",
       "      <td>0.261745</td>\n",
       "      <td>0.193289</td>\n",
       "      <td>0.159732</td>\n",
       "      <td>0.259060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374497</td>\n",
       "      <td>0.614765</td>\n",
       "      <td>0.245638</td>\n",
       "      <td>0.212081</td>\n",
       "      <td>0.265772</td>\n",
       "      <td>0.116779</td>\n",
       "      <td>0.397315</td>\n",
       "      <td>0.677852</td>\n",
       "      <td>0.412081</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.156208</td>\n",
       "      <td>0.217623</td>\n",
       "      <td>0.265688</td>\n",
       "      <td>0.181575</td>\n",
       "      <td>0.189586</td>\n",
       "      <td>0.242991</td>\n",
       "      <td>0.477971</td>\n",
       "      <td>0.164219</td>\n",
       "      <td>0.373832</td>\n",
       "      <td>0.415220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192256</td>\n",
       "      <td>0.445928</td>\n",
       "      <td>0.387183</td>\n",
       "      <td>0.304406</td>\n",
       "      <td>0.249666</td>\n",
       "      <td>0.284379</td>\n",
       "      <td>0.269693</td>\n",
       "      <td>0.118825</td>\n",
       "      <td>0.137517</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.580429</td>\n",
       "      <td>0.321716</td>\n",
       "      <td>0.312332</td>\n",
       "      <td>0.108579</td>\n",
       "      <td>0.191689</td>\n",
       "      <td>0.678284</td>\n",
       "      <td>0.159517</td>\n",
       "      <td>0.364611</td>\n",
       "      <td>0.332440</td>\n",
       "      <td>0.312332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042895</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300268</td>\n",
       "      <td>0.233244</td>\n",
       "      <td>0.166220</td>\n",
       "      <td>0.441019</td>\n",
       "      <td>0.277480</td>\n",
       "      <td>0.128686</td>\n",
       "      <td>0.292225</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.621333</td>\n",
       "      <td>0.329333</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.524000</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.385333</td>\n",
       "      <td>0.225333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.230667</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.529333</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>0.206667</td>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.341333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.347185</td>\n",
       "      <td>0.320375</td>\n",
       "      <td>0.076408</td>\n",
       "      <td>0.025469</td>\n",
       "      <td>0.117962</td>\n",
       "      <td>0.293566</td>\n",
       "      <td>0.536193</td>\n",
       "      <td>0.202413</td>\n",
       "      <td>0.131367</td>\n",
       "      <td>0.556300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206434</td>\n",
       "      <td>0.280161</td>\n",
       "      <td>0.324397</td>\n",
       "      <td>0.396783</td>\n",
       "      <td>0.116622</td>\n",
       "      <td>0.238606</td>\n",
       "      <td>0.420912</td>\n",
       "      <td>0.331099</td>\n",
       "      <td>0.391421</td>\n",
       "      <td>0.343164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1016 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CIR0      CIR1      CIR2      CIR3      CIR4      CIR5      CIR6  \\\n",
       "0  0.173154  0.418792  0.444295  0.189262  0.214765  0.655034  0.261745   \n",
       "1  0.156208  0.217623  0.265688  0.181575  0.189586  0.242991  0.477971   \n",
       "2  0.580429  0.321716  0.312332  0.108579  0.191689  0.678284  0.159517   \n",
       "3  0.621333  0.329333  0.542667  0.300000  0.372000  0.092000  0.524000   \n",
       "4  0.347185  0.320375  0.076408  0.025469  0.117962  0.293566  0.536193   \n",
       "\n",
       "       CIR7      CIR8      CIR9  ...   CIR1006   CIR1007   CIR1008   CIR1009  \\\n",
       "0  0.193289  0.159732  0.259060  ...  0.374497  0.614765  0.245638  0.212081   \n",
       "1  0.164219  0.373832  0.415220  ...  0.192256  0.445928  0.387183  0.304406   \n",
       "2  0.364611  0.332440  0.312332  ...  0.042895  0.500000  0.300268  0.233244   \n",
       "3  0.581333  0.385333  0.225333  ...  0.336000  0.230667  0.264000  0.213333   \n",
       "4  0.202413  0.131367  0.556300  ...  0.206434  0.280161  0.324397  0.396783   \n",
       "\n",
       "    CIR1010   CIR1011   CIR1012   CIR1013   CIR1014   CIR1015  \n",
       "0  0.265772  0.116779  0.397315  0.677852  0.412081  0.000000  \n",
       "1  0.249666  0.284379  0.269693  0.118825  0.137517  0.000000  \n",
       "2  0.166220  0.441019  0.277480  0.128686  0.292225  0.000000  \n",
       "3  0.578667  0.529333  0.386667  0.206667  0.456000  0.341333  \n",
       "4  0.116622  0.238606  0.420912  0.331099  0.391421  0.343164  \n",
       "\n",
       "[5 rows x 1016 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uwb_data = df_uwb[[\"CIR\"+str(i) for i in range(cir_n)]]\n",
    "print(\"UWB DataFrame X for Trainndarray shape : \",df_uwb_data.values.shape)\n",
    "df_uwb_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:17.368433Z",
     "start_time": "2022-02-01T13:18:16.927026Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_uwb_data.values, df_uwb['NLOS'].values, test_size=0.1, random_state=random_seed, stratify=df_uwb['NLOS'].values)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=random_seed, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split (Train, Validation, Test) x, label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:17.384484Z",
     "start_time": "2022-02-01T13:18:17.368433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape : (34020, 1016) (34020,)\n",
      "x_val shape : (3780, 1016) (3780,)\n",
      "x_test shape : (4200, 1016) (4200,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape :\", x_train.shape, y_train.shape)\n",
    "print(\"x_val shape :\", x_val.shape, y_val.shape)\n",
    "print(\"x_test shape :\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:17.400488Z",
     "start_time": "2022-02-01T13:18:17.385485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train NLOS 0 count : 17010\n",
      "Train NLOS 1 count : 17010\n",
      "Validation NLOS 0 count : 1890\n",
      "Validation NLOS 1 count : 1890\n",
      "Test NLOS 0 count : 2100\n",
      "Test NLOS 0 count : 2100\n"
     ]
    }
   ],
   "source": [
    "print(\"Train NLOS 0 count :\", len(y_train[y_train==0]))\n",
    "print(\"Train NLOS 1 count :\", len(y_train[y_train==1]))\n",
    "print(\"Validation NLOS 0 count :\", len(y_val[y_val==0]))\n",
    "print(\"Validation NLOS 1 count :\", len(y_val[y_val==1]))\n",
    "print(\"Test NLOS 0 count :\", len(y_test[y_test==0]))\n",
    "print(\"Test NLOS 0 count :\", len(y_test[y_test==1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:17.416491Z",
     "start_time": "2022-02-01T13:18:17.401488Z"
    }
   },
   "outputs": [],
   "source": [
    "def generating_loader(x_data, y_data, batch_size=batch_size, shuffle=True, drop_last=True):\n",
    "    # preprocessing x_data\n",
    "    x_data = np.expand_dims(x_data, axis=1)\n",
    "    x_tensor = torch.tensor(x_data, dtype=torch.float32)\n",
    "    # preprocessing y_data\n",
    "    y_tensor = torch.tensor(y_data, dtype=torch.long).view(-1)\n",
    "\n",
    "    return DataLoader(TensorDataset(x_tensor, y_tensor), batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:17.448499Z",
     "start_time": "2022-02-01T13:18:17.417492Z"
    }
   },
   "outputs": [],
   "source": [
    "trainloader = generating_loader(x_train, y_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "validationloader = generating_loader(x_val, y_val, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "testloader = generating_loader(x_val, y_val, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:17.464502Z",
     "start_time": "2022-02-01T13:18:17.449499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 1016]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for x, label in trainloader:\n",
    "    print(x.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:17.480506Z",
     "start_time": "2022-02-01T13:18:17.465503Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, batch_size, num_layers, fully_connected, device):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.conv1d_layer = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=in_channels, out_channels=10, kernel_size=4, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=10, out_channels=20, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "        ) \n",
    "        self.lstm = nn.LSTM(input_size = 504, \n",
    "                            hidden_size = 32, \n",
    "                            num_layers = num_layers,\n",
    "                            bias = False,\n",
    "                            dropout = 0.5,\n",
    "                            bidirectional = True,\n",
    "                            batch_first=True)\n",
    "\n",
    "        self.hidden_state, self.cell_state = self.init_hidden()\n",
    "        \n",
    "        self.bn = nn.BatchNorm1d(64)\n",
    "        self.fc_layer = nn.Linear(64, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_layer_class = nn.Linear(128, out_channels)\n",
    "\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden_state = torch.zeros(num_layers*2, self.batch_size, 32).to(device)\n",
    "        cell_state = torch.zeros(num_layers*2, self.batch_size, 32).to(device)\n",
    "\n",
    "        return hidden_state, cell_state\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1d_layer(x)\n",
    "        x, _ = self.lstm(x,(self.hidden_state, self.cell_state))\n",
    "        x = x[:, -1 :].view(x.size(0), -1)\n",
    "        x = self.bn(x)\n",
    "        x = self.fc_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc_layer_class(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:18:19.492178Z",
     "start_time": "2022-02-01T13:18:17.481506Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN_LSTM(\n",
    "    in_channels=in_channels,\\\n",
    "    device=device,\\\n",
    "    out_channels=num_classes,\\\n",
    "    batch_size=batch_size,\\\n",
    "    fully_connected=fully_connected,\\\n",
    "    num_layers=num_layers).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)  # optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:23:33.455590Z",
     "start_time": "2022-02-01T13:18:19.492178Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Train Start!!*\n",
      "epoch : 100, learing rate : 0.001, device : NVIDIA GeForce RTX 2060 SUPER\n",
      "Model : CNN_LSTM\n",
      "Loss function : CrossEntropyLoss\n",
      "Optimizer : Adam ( Parameter Group 0, amsgrad: False, betas: (0.9, 0.999), eps: 1e-08, lr: 0.001, weight_decay: 0.0 )\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yoon\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] (1, 0) loss = 0.68704, Accuracy = 0.6875, lr=0.001000\n",
      "[Train] (1, 100) loss = 0.42302, Accuracy = 0.7422, lr=0.001000\n",
      "[Train] (1, 200) loss = 0.35409, Accuracy = 0.7969, lr=0.001000\n",
      "[Train] (1, 300) loss = 0.41555, Accuracy = 0.7930, lr=0.001000\n",
      "[Train] (1, 400) loss = 0.31510, Accuracy = 0.8125, lr=0.001000\n",
      "[Train] (1, 500) loss = 0.38404, Accuracy = 0.8073, lr=0.001000\n",
      "[Train] (2, 0) loss = 0.37173, Accuracy = 0.8147, lr=0.001000\n",
      "[Train] (2, 100) loss = 0.46200, Accuracy = 0.8125, lr=0.001000\n",
      "[Train] (2, 200) loss = 0.21119, Accuracy = 0.8229, lr=0.001000\n",
      "[Train] (2, 300) loss = 0.36068, Accuracy = 0.8234, lr=0.001000\n",
      "[Train] (2, 400) loss = 0.26921, Accuracy = 0.8324, lr=0.001000\n",
      "[Train] (2, 500) loss = 0.23369, Accuracy = 0.8385, lr=0.001000\n",
      "[Train] (3, 0) loss = 0.30426, Accuracy = 0.8425, lr=0.001000\n",
      "[Train] (3, 100) loss = 0.22138, Accuracy = 0.8482, lr=0.001000\n",
      "[Train] (3, 200) loss = 0.35889, Accuracy = 0.8458, lr=0.001000\n",
      "[Train] (3, 300) loss = 0.24684, Accuracy = 0.8486, lr=0.001000\n",
      "[Train] (3, 400) loss = 0.46946, Accuracy = 0.8474, lr=0.001000\n",
      "[Train] (3, 500) loss = 0.37296, Accuracy = 0.8446, lr=0.001000\n",
      "[Train] (4, 0) loss = 0.32468, Accuracy = 0.8429, lr=0.001000\n",
      "[Train] (4, 100) loss = 0.27635, Accuracy = 0.8445, lr=0.001000\n",
      "[Train] (4, 200) loss = 0.33637, Accuracy = 0.8445, lr=0.001000\n",
      "[Train] (4, 300) loss = 0.41574, Accuracy = 0.8416, lr=0.001000\n",
      "[Train] (4, 400) loss = 0.24529, Accuracy = 0.8438, lr=0.001000\n",
      "[Train] (4, 500) loss = 0.37204, Accuracy = 0.8431, lr=0.001000\n",
      "[Train] (5, 0) loss = 0.41412, Accuracy = 0.8419, lr=0.001000\n",
      "[Train] (5, 100) loss = 0.23923, Accuracy = 0.8444, lr=0.001000\n",
      "[Train] (5, 200) loss = 0.33140, Accuracy = 0.8449, lr=0.001000\n",
      "[Train] (5, 300) loss = 0.23890, Accuracy = 0.8465, lr=0.001000\n",
      "[Train] (5, 400) loss = 0.32278, Accuracy = 0.8470, lr=0.001000\n",
      "[Train] (5, 500) loss = 0.38779, Accuracy = 0.8464, lr=0.001000\n",
      "*[Valid] Accuracy:0.8125, Precison:0.8196, Recall:0.8125, F1 Score:0.8129\n",
      "[Train] (6, 0) loss = 0.25694, Accuracy = 0.8478, lr=0.001000\n",
      "[Train] (6, 100) loss = 0.28350, Accuracy = 0.8481, lr=0.001000\n",
      "[Train] (6, 200) loss = 0.26087, Accuracy = 0.8504, lr=0.001000\n",
      "[Train] (6, 300) loss = 0.27533, Accuracy = 0.8511, lr=0.001000\n",
      "[Train] (6, 400) loss = 0.31522, Accuracy = 0.8504, lr=0.001000\n",
      "[Train] (6, 500) loss = 0.27048, Accuracy = 0.8507, lr=0.001000\n",
      "[Train] (7, 0) loss = 0.25476, Accuracy = 0.8518, lr=0.001000\n",
      "[Train] (7, 100) loss = 0.24311, Accuracy = 0.8532, lr=0.001000\n",
      "[Train] (7, 200) loss = 0.25782, Accuracy = 0.8538, lr=0.001000\n",
      "[Train] (7, 300) loss = 0.40823, Accuracy = 0.8539, lr=0.001000\n",
      "[Train] (7, 400) loss = 0.31737, Accuracy = 0.8533, lr=0.001000\n",
      "[Train] (7, 500) loss = 0.27711, Accuracy = 0.8542, lr=0.001000\n",
      "[Train] (8, 0) loss = 0.33174, Accuracy = 0.8543, lr=0.001000\n",
      "[Train] (8, 100) loss = 0.31194, Accuracy = 0.8551, lr=0.001000\n",
      "[Train] (8, 200) loss = 0.26540, Accuracy = 0.8559, lr=0.001000\n",
      "[Train] (8, 300) loss = 0.26752, Accuracy = 0.8563, lr=0.001000\n",
      "[Train] (8, 400) loss = 0.19053, Accuracy = 0.8580, lr=0.001000\n",
      "[Train] (8, 500) loss = 0.21796, Accuracy = 0.8587, lr=0.001000\n",
      "[Train] (9, 0) loss = 0.18606, Accuracy = 0.8607, lr=0.001000\n",
      "[Train] (9, 100) loss = 0.24899, Accuracy = 0.8616, lr=0.001000\n",
      "[Train] (9, 200) loss = 0.22307, Accuracy = 0.8621, lr=0.001000\n",
      "[Train] (9, 300) loss = 0.23164, Accuracy = 0.8627, lr=0.001000\n",
      "[Train] (9, 400) loss = 0.31736, Accuracy = 0.8629, lr=0.001000\n",
      "[Train] (9, 500) loss = 0.26222, Accuracy = 0.8637, lr=0.001000\n",
      "[Train] (10, 0) loss = 0.13554, Accuracy = 0.8651, lr=0.001000\n",
      "[Train] (10, 100) loss = 0.28438, Accuracy = 0.8650, lr=0.001000\n",
      "[Train] (10, 200) loss = 0.28742, Accuracy = 0.8651, lr=0.001000\n",
      "[Train] (10, 300) loss = 0.19602, Accuracy = 0.8661, lr=0.001000\n",
      "[Train] (10, 400) loss = 0.21171, Accuracy = 0.8668, lr=0.001000\n",
      "[Train] (10, 500) loss = 0.30734, Accuracy = 0.8672, lr=0.001000\n",
      "*[Valid] Accuracy:0.7969, Precison:0.8007, Recall:0.7969, F1 Score:0.7970\n",
      "[Train] (11, 0) loss = 0.28457, Accuracy = 0.8668, lr=0.001000\n",
      "[Train] (11, 100) loss = 0.38441, Accuracy = 0.8667, lr=0.001000\n",
      "[Train] (11, 200) loss = 0.25597, Accuracy = 0.8671, lr=0.001000\n",
      "[Train] (11, 300) loss = 0.18152, Accuracy = 0.8679, lr=0.001000\n",
      "[Train] (11, 400) loss = 0.19580, Accuracy = 0.8687, lr=0.001000\n",
      "[Train] (11, 500) loss = 0.26413, Accuracy = 0.8686, lr=0.001000\n",
      "[Train] (12, 0) loss = 0.11196, Accuracy = 0.8701, lr=0.001000\n",
      "[Train] (12, 100) loss = 0.26357, Accuracy = 0.8697, lr=0.001000\n",
      "[Train] (12, 200) loss = 0.22421, Accuracy = 0.8700, lr=0.001000\n",
      "[Train] (12, 300) loss = 0.16854, Accuracy = 0.8710, lr=0.001000\n",
      "[Train] (12, 400) loss = 0.25960, Accuracy = 0.8719, lr=0.001000\n",
      "[Train] (12, 500) loss = 0.21511, Accuracy = 0.8726, lr=0.001000\n",
      "[Train] (13, 0) loss = 0.29088, Accuracy = 0.8722, lr=0.001000\n",
      "[Train] (13, 100) loss = 0.25910, Accuracy = 0.8723, lr=0.001000\n",
      "[Train] (13, 200) loss = 0.21468, Accuracy = 0.8725, lr=0.001000\n",
      "[Train] (13, 300) loss = 0.15351, Accuracy = 0.8736, lr=0.001000\n",
      "[Train] (13, 400) loss = 0.16109, Accuracy = 0.8744, lr=0.001000\n",
      "[Train] (13, 500) loss = 0.26129, Accuracy = 0.8748, lr=0.001000\n",
      "[Train] (14, 0) loss = 0.23169, Accuracy = 0.8746, lr=0.001000\n",
      "[Train] (14, 100) loss = 0.20966, Accuracy = 0.8748, lr=0.001000\n",
      "[Train] (14, 200) loss = 0.18765, Accuracy = 0.8756, lr=0.001000\n",
      "[Train] (14, 300) loss = 0.14362, Accuracy = 0.8763, lr=0.001000\n",
      "[Train] (14, 400) loss = 0.22426, Accuracy = 0.8765, lr=0.001000\n",
      "[Train] (14, 500) loss = 0.15821, Accuracy = 0.8774, lr=0.001000\n",
      "[Train] (15, 0) loss = 0.25259, Accuracy = 0.8778, lr=0.001000\n",
      "[Train] (15, 100) loss = 0.21156, Accuracy = 0.8781, lr=0.001000\n",
      "[Train] (15, 200) loss = 0.18127, Accuracy = 0.8784, lr=0.001000\n",
      "[Train] (15, 300) loss = 0.22459, Accuracy = 0.8789, lr=0.001000\n",
      "[Train] (15, 400) loss = 0.22107, Accuracy = 0.8785, lr=0.001000\n",
      "[Train] (15, 500) loss = 0.28453, Accuracy = 0.8783, lr=0.001000\n",
      "*[Valid] Accuracy:0.8125, Precison:0.8196, Recall:0.8125, F1 Score:0.8129\n",
      "[Train] (16, 0) loss = 0.13705, Accuracy = 0.8789, lr=0.001000\n",
      "[Train] (16, 100) loss = 0.14148, Accuracy = 0.8796, lr=0.001000\n",
      "[Train] (16, 200) loss = 0.15309, Accuracy = 0.8800, lr=0.001000\n",
      "[Train] (16, 300) loss = 0.13799, Accuracy = 0.8807, lr=0.001000\n",
      "[Train] (16, 400) loss = 0.18364, Accuracy = 0.8809, lr=0.001000\n",
      "[Train] (16, 500) loss = 0.17116, Accuracy = 0.8820, lr=0.001000\n",
      "[Train] (17, 0) loss = 0.21742, Accuracy = 0.8822, lr=0.001000\n",
      "[Train] (17, 100) loss = 0.14215, Accuracy = 0.8828, lr=0.001000\n",
      "[Train] (17, 200) loss = 0.22625, Accuracy = 0.8834, lr=0.001000\n",
      "[Train] (17, 300) loss = 0.13772, Accuracy = 0.8842, lr=0.001000\n",
      "[Train] (17, 400) loss = 0.19472, Accuracy = 0.8846, lr=0.001000\n",
      "[Train] (17, 500) loss = 0.13288, Accuracy = 0.8853, lr=0.001000\n",
      "[Train] (18, 0) loss = 0.18423, Accuracy = 0.8856, lr=0.001000\n",
      "[Train] (18, 100) loss = 0.15871, Accuracy = 0.8858, lr=0.001000\n",
      "[Train] (18, 200) loss = 0.04421, Accuracy = 0.8869, lr=0.001000\n",
      "[Train] (18, 300) loss = 0.15356, Accuracy = 0.8874, lr=0.001000\n",
      "[Train] (18, 400) loss = 0.12077, Accuracy = 0.8880, lr=0.001000\n",
      "[Train] (18, 500) loss = 0.21889, Accuracy = 0.8882, lr=0.001000\n",
      "[Train] (19, 0) loss = 0.10066, Accuracy = 0.8890, lr=0.001000\n",
      "[Train] (19, 100) loss = 0.17812, Accuracy = 0.8892, lr=0.001000\n",
      "[Train] (19, 200) loss = 0.06657, Accuracy = 0.8901, lr=0.001000\n",
      "[Train] (19, 300) loss = 0.09748, Accuracy = 0.8908, lr=0.001000\n",
      "[Train] (19, 400) loss = 0.21818, Accuracy = 0.8910, lr=0.001000\n",
      "[Train] (19, 500) loss = 0.15549, Accuracy = 0.8914, lr=0.001000\n",
      "[Train] (20, 0) loss = 0.10095, Accuracy = 0.8923, lr=0.001000\n",
      "[Train] (20, 100) loss = 0.10010, Accuracy = 0.8928, lr=0.001000\n",
      "[Train] (20, 200) loss = 0.09559, Accuracy = 0.8934, lr=0.001000\n",
      "[Train] (20, 300) loss = 0.12461, Accuracy = 0.8938, lr=0.001000\n",
      "[Train] (20, 400) loss = 0.15666, Accuracy = 0.8939, lr=0.001000\n",
      "[Train] (20, 500) loss = 0.14415, Accuracy = 0.8941, lr=0.001000\n",
      "*[Valid] Accuracy:0.8125, Precison:0.8125, Recall:0.8125, F1 Score:0.8125\n",
      "[Train] (21, 0) loss = 0.06739, Accuracy = 0.8948, lr=0.001000\n",
      "[Train] (21, 100) loss = 0.07098, Accuracy = 0.8952, lr=0.001000\n",
      "[Train] (21, 200) loss = 0.06526, Accuracy = 0.8960, lr=0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] (21, 300) loss = 0.10178, Accuracy = 0.8964, lr=0.001000\n",
      "[Train] (21, 400) loss = 0.16373, Accuracy = 0.8965, lr=0.001000\n",
      "[Train] (21, 500) loss = 0.12930, Accuracy = 0.8967, lr=0.001000\n",
      "[Train] (22, 0) loss = 0.14030, Accuracy = 0.8968, lr=0.001000\n",
      "[Train] (22, 100) loss = 0.10002, Accuracy = 0.8975, lr=0.001000\n",
      "[Train] (22, 200) loss = 0.16078, Accuracy = 0.8979, lr=0.001000\n",
      "[Train] (22, 300) loss = 0.13422, Accuracy = 0.8981, lr=0.001000\n",
      "[Train] (22, 400) loss = 0.04532, Accuracy = 0.8987, lr=0.001000\n",
      "[Train] (22, 500) loss = 0.13417, Accuracy = 0.8989, lr=0.001000\n",
      "[Train] (23, 0) loss = 0.15267, Accuracy = 0.8991, lr=0.001000\n",
      "[Train] (23, 100) loss = 0.10074, Accuracy = 0.8996, lr=0.001000\n",
      "[Train] (23, 200) loss = 0.11810, Accuracy = 0.9000, lr=0.001000\n",
      "[Train] (23, 300) loss = 0.09764, Accuracy = 0.9004, lr=0.001000\n",
      "[Train] (23, 400) loss = 0.24308, Accuracy = 0.9004, lr=0.001000\n",
      "[Train] (23, 500) loss = 0.10336, Accuracy = 0.9008, lr=0.001000\n",
      "[Train] (24, 0) loss = 0.12146, Accuracy = 0.9012, lr=0.001000\n",
      "[Train] (24, 100) loss = 0.10641, Accuracy = 0.9015, lr=0.001000\n",
      "[Train] (24, 200) loss = 0.09957, Accuracy = 0.9017, lr=0.001000\n",
      "[Train] (24, 300) loss = 0.16339, Accuracy = 0.9022, lr=0.001000\n",
      "[Train] (24, 400) loss = 0.07845, Accuracy = 0.9028, lr=0.001000\n",
      "[Train] (24, 500) loss = 0.06287, Accuracy = 0.9032, lr=0.001000\n",
      "[Train] (25, 0) loss = 0.10811, Accuracy = 0.9037, lr=0.001000\n",
      "[Train] (25, 100) loss = 0.08463, Accuracy = 0.9040, lr=0.001000\n",
      "[Train] (25, 200) loss = 0.06599, Accuracy = 0.9045, lr=0.001000\n",
      "[Train] (25, 300) loss = 0.04919, Accuracy = 0.9050, lr=0.001000\n",
      "[Train] (25, 400) loss = 0.03675, Accuracy = 0.9056, lr=0.001000\n",
      "[Train] (25, 500) loss = 0.11338, Accuracy = 0.9059, lr=0.001000\n",
      "*[Valid] Accuracy:0.8125, Precison:0.8141, Recall:0.8125, F1 Score:0.8125\n",
      "[Train] (26, 0) loss = 0.05474, Accuracy = 0.9062, lr=0.001000\n",
      "[Train] (26, 100) loss = 0.02698, Accuracy = 0.9069, lr=0.001000\n",
      "[Train] (26, 200) loss = 0.03297, Accuracy = 0.9075, lr=0.001000\n",
      "[Train] (26, 300) loss = 0.08794, Accuracy = 0.9079, lr=0.001000\n",
      "[Train] (26, 400) loss = 0.04805, Accuracy = 0.9084, lr=0.001000\n",
      "[Train] (26, 500) loss = 0.16777, Accuracy = 0.9085, lr=0.001000\n",
      "[Train] (27, 0) loss = 0.04536, Accuracy = 0.9089, lr=0.001000\n",
      "[Train] (27, 100) loss = 0.05787, Accuracy = 0.9094, lr=0.001000\n",
      "[Train] (27, 200) loss = 0.04626, Accuracy = 0.9099, lr=0.001000\n",
      "[Train] (27, 300) loss = 0.02106, Accuracy = 0.9104, lr=0.001000\n",
      "[Train] (27, 400) loss = 0.00979, Accuracy = 0.9110, lr=0.001000\n",
      "[Train] (27, 500) loss = 0.09566, Accuracy = 0.9113, lr=0.001000\n",
      "[Train] (28, 0) loss = 0.02996, Accuracy = 0.9117, lr=0.001000\n",
      "[Train] (28, 100) loss = 0.04542, Accuracy = 0.9121, lr=0.001000\n",
      "[Train] (28, 200) loss = 0.03532, Accuracy = 0.9125, lr=0.001000\n",
      "[Train] (28, 300) loss = 0.07693, Accuracy = 0.9127, lr=0.001000\n",
      "[Train] (28, 400) loss = 0.07274, Accuracy = 0.9131, lr=0.001000\n",
      "[Train] (28, 500) loss = 0.01261, Accuracy = 0.9136, lr=0.001000\n",
      "[Train] (29, 0) loss = 0.06306, Accuracy = 0.9140, lr=0.001000\n",
      "[Train] (29, 100) loss = 0.02530, Accuracy = 0.9144, lr=0.001000\n",
      "[Train] (29, 200) loss = 0.04543, Accuracy = 0.9148, lr=0.001000\n",
      "[Train] (29, 300) loss = 0.10523, Accuracy = 0.9152, lr=0.001000\n",
      "[Train] (29, 400) loss = 0.01612, Accuracy = 0.9156, lr=0.001000\n",
      "[Train] (29, 500) loss = 0.03530, Accuracy = 0.9160, lr=0.001000\n",
      "[Train] (30, 0) loss = 0.08432, Accuracy = 0.9162, lr=0.001000\n",
      "[Train] (30, 100) loss = 0.03566, Accuracy = 0.9165, lr=0.001000\n",
      "[Train] (30, 200) loss = 0.04872, Accuracy = 0.9169, lr=0.001000\n",
      "[Train] (30, 300) loss = 0.02301, Accuracy = 0.9173, lr=0.001000\n",
      "[Train] (30, 400) loss = 0.06755, Accuracy = 0.9177, lr=0.001000\n",
      "[Train] (30, 500) loss = 0.01703, Accuracy = 0.9181, lr=0.001000\n",
      "*[Valid] Accuracy:0.8125, Precison:0.8125, Recall:0.8125, F1 Score:0.8125\n",
      "[Train] (31, 0) loss = 0.02309, Accuracy = 0.9185, lr=0.001000\n",
      "[Train] (31, 100) loss = 0.08676, Accuracy = 0.9186, lr=0.001000\n",
      "[Train] (31, 200) loss = 0.03123, Accuracy = 0.9190, lr=0.001000\n",
      "[Train] (31, 300) loss = 0.09157, Accuracy = 0.9192, lr=0.001000\n",
      "[Train] (31, 400) loss = 0.05984, Accuracy = 0.9196, lr=0.001000\n",
      "[Train] (31, 500) loss = 0.00977, Accuracy = 0.9200, lr=0.001000\n",
      "[Train] (32, 0) loss = 0.04205, Accuracy = 0.9203, lr=0.001000\n",
      "[Train] (32, 100) loss = 0.01498, Accuracy = 0.9207, lr=0.001000\n",
      "[Train] (32, 200) loss = 0.19674, Accuracy = 0.9207, lr=0.001000\n",
      "[Train] (32, 300) loss = 0.00451, Accuracy = 0.9211, lr=0.001000\n",
      "[Train] (32, 400) loss = 0.10681, Accuracy = 0.9213, lr=0.001000\n",
      "[Train] (32, 500) loss = 0.01730, Accuracy = 0.9217, lr=0.001000\n",
      "[Train] (33, 0) loss = 0.00919, Accuracy = 0.9221, lr=0.001000\n",
      "[Train] (33, 100) loss = 0.00361, Accuracy = 0.9225, lr=0.001000\n",
      "[Train] (33, 200) loss = 0.03971, Accuracy = 0.9228, lr=0.001000\n",
      "[Train] (33, 300) loss = 0.02269, Accuracy = 0.9232, lr=0.001000\n",
      "[Train] (33, 400) loss = 0.12264, Accuracy = 0.9232, lr=0.001000\n",
      "[Train] (33, 500) loss = 0.09613, Accuracy = 0.9235, lr=0.001000\n",
      "[Train] (34, 0) loss = 0.01968, Accuracy = 0.9239, lr=0.001000\n",
      "[Train] (34, 100) loss = 0.01117, Accuracy = 0.9243, lr=0.001000\n",
      "[Train] (34, 200) loss = 0.01557, Accuracy = 0.9247, lr=0.001000\n",
      "[Train] (34, 300) loss = 0.02290, Accuracy = 0.9250, lr=0.001000\n",
      "[Train] (34, 400) loss = 0.00716, Accuracy = 0.9253, lr=0.001000\n",
      "[Train] (34, 500) loss = 0.01919, Accuracy = 0.9256, lr=0.001000\n",
      "[Train] (35, 0) loss = 0.00398, Accuracy = 0.9260, lr=0.001000\n",
      "[Train] (35, 100) loss = 0.04764, Accuracy = 0.9262, lr=0.001000\n",
      "[Train] (35, 200) loss = 0.00471, Accuracy = 0.9266, lr=0.001000\n",
      "[Train] (35, 300) loss = 0.01868, Accuracy = 0.9269, lr=0.001000\n",
      "[Train] (35, 400) loss = 0.00668, Accuracy = 0.9273, lr=0.001000\n",
      "[Train] (35, 500) loss = 0.03311, Accuracy = 0.9275, lr=0.001000\n",
      "*[Valid] Accuracy:0.8125, Precison:0.8125, Recall:0.8125, F1 Score:0.8125\n",
      "[Train] (36, 0) loss = 0.00288, Accuracy = 0.9279, lr=0.001000\n",
      "[Train] (36, 100) loss = 0.02382, Accuracy = 0.9281, lr=0.001000\n",
      "[Train] (36, 200) loss = 0.01862, Accuracy = 0.9284, lr=0.001000\n",
      "[Train] (36, 300) loss = 0.14462, Accuracy = 0.9286, lr=0.001000\n",
      "[Train] (36, 400) loss = 0.00460, Accuracy = 0.9289, lr=0.001000\n",
      "[Train] (36, 500) loss = 0.00764, Accuracy = 0.9293, lr=0.001000\n",
      "[Train] (37, 0) loss = 0.00488, Accuracy = 0.9296, lr=0.001000\n",
      "[Train] (37, 100) loss = 0.00264, Accuracy = 0.9299, lr=0.001000\n",
      "[Train] (37, 200) loss = 0.00296, Accuracy = 0.9302, lr=0.001000\n",
      "[Train] (37, 300) loss = 0.02284, Accuracy = 0.9305, lr=0.001000\n",
      "[Train] (37, 400) loss = 0.02159, Accuracy = 0.9307, lr=0.001000\n",
      "[Train] (37, 500) loss = 0.26928, Accuracy = 0.9308, lr=0.001000\n",
      "[Train] (38, 0) loss = 0.00080, Accuracy = 0.9311, lr=0.001000\n",
      "[Train] (38, 100) loss = 0.00070, Accuracy = 0.9314, lr=0.001000\n",
      "[Train] (38, 200) loss = 0.01091, Accuracy = 0.9317, lr=0.001000\n",
      "[Train] (38, 300) loss = 0.01849, Accuracy = 0.9320, lr=0.001000\n",
      "[Train] (38, 400) loss = 0.01610, Accuracy = 0.9322, lr=0.001000\n",
      "[Train] (38, 500) loss = 0.00182, Accuracy = 0.9325, lr=0.001000\n",
      "[Train] (39, 0) loss = 0.06290, Accuracy = 0.9327, lr=0.001000\n",
      "[Train] (39, 100) loss = 0.00706, Accuracy = 0.9329, lr=0.001000\n",
      "[Train] (39, 200) loss = 0.01839, Accuracy = 0.9332, lr=0.001000\n",
      "[Train] (39, 300) loss = 0.00748, Accuracy = 0.9335, lr=0.001000\n",
      "[Train] (39, 400) loss = 0.00076, Accuracy = 0.9337, lr=0.001000\n",
      "[Train] (39, 500) loss = 0.01159, Accuracy = 0.9340, lr=0.001000\n",
      "[Train] (40, 0) loss = 0.00211, Accuracy = 0.9343, lr=0.001000\n",
      "[Train] (40, 100) loss = 0.01436, Accuracy = 0.9345, lr=0.001000\n",
      "[Train] (40, 200) loss = 0.04586, Accuracy = 0.9347, lr=0.001000\n",
      "[Train] (40, 300) loss = 0.01286, Accuracy = 0.9350, lr=0.001000\n",
      "[Train] (40, 400) loss = 0.02680, Accuracy = 0.9352, lr=0.001000\n",
      "[Train] (40, 500) loss = 0.02624, Accuracy = 0.9354, lr=0.001000\n",
      "*[Valid] Accuracy:0.7969, Precison:0.7972, Recall:0.7969, F1 Score:0.7968\n",
      "[Train] (41, 0) loss = 0.05451, Accuracy = 0.9356, lr=0.001000\n",
      "[Train] (41, 100) loss = 0.01327, Accuracy = 0.9359, lr=0.001000\n",
      "[Train] (41, 200) loss = 0.03931, Accuracy = 0.9361, lr=0.001000\n",
      "[Train] (41, 300) loss = 0.00330, Accuracy = 0.9363, lr=0.001000\n",
      "[Train] (41, 400) loss = 0.00082, Accuracy = 0.9366, lr=0.001000\n",
      "[Train] (41, 500) loss = 0.00190, Accuracy = 0.9369, lr=0.001000\n",
      "[Train] (42, 0) loss = 0.01799, Accuracy = 0.9371, lr=0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] (42, 100) loss = 0.02597, Accuracy = 0.9372, lr=0.001000\n",
      "[Train] (42, 200) loss = 0.04623, Accuracy = 0.9374, lr=0.001000\n",
      "[Train] (42, 300) loss = 0.00569, Accuracy = 0.9377, lr=0.001000\n",
      "[Train] (42, 400) loss = 0.01400, Accuracy = 0.9379, lr=0.001000\n",
      "[Train] (42, 500) loss = 0.00251, Accuracy = 0.9382, lr=0.001000\n",
      "[Train] (43, 0) loss = 0.01118, Accuracy = 0.9384, lr=0.001000\n",
      "[Train] (43, 100) loss = 0.00433, Accuracy = 0.9387, lr=0.001000\n",
      "[Train] (43, 200) loss = 0.06997, Accuracy = 0.9388, lr=0.001000\n",
      "[Train] (43, 300) loss = 0.10664, Accuracy = 0.9389, lr=0.001000\n",
      "[Train] (43, 400) loss = 0.00220, Accuracy = 0.9391, lr=0.001000\n",
      "[Train] (43, 500) loss = 0.01543, Accuracy = 0.9394, lr=0.001000\n",
      "[Train] (44, 0) loss = 0.01614, Accuracy = 0.9396, lr=0.001000\n",
      "[Train] (44, 100) loss = 0.00023, Accuracy = 0.9398, lr=0.001000\n",
      "[Train] (44, 200) loss = 0.01206, Accuracy = 0.9401, lr=0.001000\n",
      "[Train] (44, 300) loss = 0.00054, Accuracy = 0.9403, lr=0.001000\n",
      "[Train] (44, 400) loss = 0.01822, Accuracy = 0.9405, lr=0.001000\n",
      "[Train] (44, 500) loss = 0.07018, Accuracy = 0.9407, lr=0.001000\n",
      "[Train] (45, 0) loss = 0.04876, Accuracy = 0.9409, lr=0.001000\n",
      "[Train] (45, 100) loss = 0.00140, Accuracy = 0.9411, lr=0.001000\n",
      "[Train] (45, 200) loss = 0.00379, Accuracy = 0.9413, lr=0.001000\n",
      "[Train] (45, 300) loss = 0.03756, Accuracy = 0.9415, lr=0.001000\n",
      "[Train] (45, 400) loss = 0.00293, Accuracy = 0.9417, lr=0.001000\n",
      "[Train] (45, 500) loss = 0.00812, Accuracy = 0.9419, lr=0.001000\n",
      "*[Valid] Accuracy:0.7969, Precison:0.8007, Recall:0.7969, F1 Score:0.7970\n",
      "[Train] (46, 0) loss = 0.04251, Accuracy = 0.9421, lr=0.001000\n",
      "[Train] (46, 100) loss = 0.00353, Accuracy = 0.9423, lr=0.001000\n",
      "[Train] (46, 200) loss = 0.00080, Accuracy = 0.9425, lr=0.001000\n",
      "[Train] (46, 300) loss = 0.00816, Accuracy = 0.9427, lr=0.001000\n",
      "[Train] (46, 400) loss = 0.00095, Accuracy = 0.9429, lr=0.001000\n",
      "[Train] (46, 500) loss = 0.00384, Accuracy = 0.9431, lr=0.001000\n",
      "[Train] (47, 0) loss = 0.01045, Accuracy = 0.9433, lr=0.001000\n",
      "[Train] (47, 100) loss = 0.02948, Accuracy = 0.9435, lr=0.001000\n",
      "[Train] (47, 200) loss = 0.00119, Accuracy = 0.9437, lr=0.001000\n",
      "[Train] (47, 300) loss = 0.00876, Accuracy = 0.9439, lr=0.001000\n",
      "[Train] (47, 400) loss = 0.00565, Accuracy = 0.9441, lr=0.001000\n",
      "[Train] (47, 500) loss = 0.01897, Accuracy = 0.9442, lr=0.001000\n",
      "[Train] (48, 0) loss = 0.00439, Accuracy = 0.9444, lr=0.001000\n",
      "[Train] (48, 100) loss = 0.00123, Accuracy = 0.9446, lr=0.001000\n",
      "[Train] (48, 200) loss = 0.02204, Accuracy = 0.9447, lr=0.001000\n",
      "[Train] (48, 300) loss = 0.03161, Accuracy = 0.9449, lr=0.001000\n",
      "[Train] (48, 400) loss = 0.00519, Accuracy = 0.9451, lr=0.001000\n",
      "[Train] (48, 500) loss = 0.00300, Accuracy = 0.9453, lr=0.001000\n",
      "[Train] (49, 0) loss = 0.00432, Accuracy = 0.9454, lr=0.001000\n",
      "[Train] (49, 100) loss = 0.00337, Accuracy = 0.9456, lr=0.001000\n",
      "[Train] (49, 200) loss = 0.00399, Accuracy = 0.9458, lr=0.001000\n",
      "[Train] (49, 300) loss = 0.04272, Accuracy = 0.9460, lr=0.001000\n",
      "[Train] (49, 400) loss = 0.04147, Accuracy = 0.9461, lr=0.001000\n",
      "[Train] (49, 500) loss = 0.00413, Accuracy = 0.9463, lr=0.001000\n",
      "[Train] (50, 0) loss = 0.00257, Accuracy = 0.9465, lr=0.001000\n",
      "[Train] (50, 100) loss = 0.00798, Accuracy = 0.9466, lr=0.001000\n",
      "[Train] (50, 200) loss = 0.00104, Accuracy = 0.9468, lr=0.001000\n",
      "[Train] (50, 300) loss = 0.01548, Accuracy = 0.9469, lr=0.001000\n",
      "[Train] (50, 400) loss = 0.00058, Accuracy = 0.9471, lr=0.001000\n",
      "[Train] (50, 500) loss = 0.00407, Accuracy = 0.9473, lr=0.001000\n",
      "*[Valid] Accuracy:0.8281, Precison:0.8395, Recall:0.8281, F1 Score:0.8288\n",
      "[Train] (51, 0) loss = 0.00120, Accuracy = 0.9475, lr=0.001000\n",
      "[Train] (51, 100) loss = 0.00115, Accuracy = 0.9476, lr=0.001000\n",
      "[Train] (51, 200) loss = 0.00286, Accuracy = 0.9478, lr=0.001000\n",
      "[Train] (51, 300) loss = 0.00587, Accuracy = 0.9480, lr=0.001000\n",
      "[Train] (51, 400) loss = 0.00117, Accuracy = 0.9482, lr=0.001000\n",
      "[Train] (51, 500) loss = 0.01332, Accuracy = 0.9483, lr=0.001000\n",
      "[Train] (52, 0) loss = 0.00276, Accuracy = 0.9485, lr=0.001000\n",
      "[Train] (52, 100) loss = 0.01958, Accuracy = 0.9487, lr=0.001000\n",
      "[Train] (52, 200) loss = 0.00231, Accuracy = 0.9488, lr=0.001000\n",
      "[Train] (52, 300) loss = 0.03706, Accuracy = 0.9489, lr=0.001000\n",
      "[Train] (52, 400) loss = 0.00107, Accuracy = 0.9491, lr=0.001000\n",
      "[Train] (52, 500) loss = 0.00183, Accuracy = 0.9492, lr=0.001000\n",
      "[Train] (53, 0) loss = 0.00983, Accuracy = 0.9494, lr=0.001000\n",
      "[Train] (53, 100) loss = 0.01083, Accuracy = 0.9495, lr=0.001000\n",
      "[Train] (53, 200) loss = 0.00057, Accuracy = 0.9497, lr=0.001000\n",
      "[Train] (53, 300) loss = 0.00071, Accuracy = 0.9499, lr=0.001000\n",
      "[Train] (53, 400) loss = 0.00141, Accuracy = 0.9500, lr=0.001000\n",
      "[Train] (53, 500) loss = 0.00274, Accuracy = 0.9502, lr=0.001000\n",
      "[Train] (54, 0) loss = 0.00137, Accuracy = 0.9503, lr=0.001000\n",
      "[Train] (54, 100) loss = 0.00586, Accuracy = 0.9505, lr=0.001000\n",
      "[Train] (54, 200) loss = 0.01884, Accuracy = 0.9506, lr=0.001000\n",
      "[Train] (54, 300) loss = 0.02539, Accuracy = 0.9507, lr=0.001000\n",
      "[Train] (54, 400) loss = 0.00433, Accuracy = 0.9509, lr=0.001000\n",
      "[Train] (54, 500) loss = 0.01221, Accuracy = 0.9510, lr=0.001000\n",
      "[Train] (55, 0) loss = 0.00057, Accuracy = 0.9511, lr=0.001000\n",
      "[Train] (55, 100) loss = 0.00414, Accuracy = 0.9513, lr=0.001000\n",
      "[Train] (55, 200) loss = 0.00636, Accuracy = 0.9514, lr=0.001000\n",
      "[Train] (55, 300) loss = 0.01000, Accuracy = 0.9516, lr=0.001000\n",
      "[Train] (55, 400) loss = 0.01900, Accuracy = 0.9517, lr=0.001000\n",
      "[Train] (55, 500) loss = 0.02166, Accuracy = 0.9518, lr=0.001000\n",
      "*[Valid] Accuracy:0.8438, Precison:0.8454, Recall:0.8438, F1 Score:0.8438\n",
      "[Train] (56, 0) loss = 0.04786, Accuracy = 0.9519, lr=0.001000\n",
      "[Train] (56, 100) loss = 0.00158, Accuracy = 0.9520, lr=0.001000\n",
      "[Train] (56, 200) loss = 0.00100, Accuracy = 0.9521, lr=0.001000\n",
      "[Train] (56, 300) loss = 0.07299, Accuracy = 0.9522, lr=0.001000\n",
      "[Train] (56, 400) loss = 0.00359, Accuracy = 0.9523, lr=0.001000\n",
      "[Train] (56, 500) loss = 0.00015, Accuracy = 0.9525, lr=0.001000\n",
      "[Train] (57, 0) loss = 0.02641, Accuracy = 0.9526, lr=0.001000\n",
      "[Train] (57, 100) loss = 0.00099, Accuracy = 0.9528, lr=0.001000\n",
      "[Train] (57, 200) loss = 0.07917, Accuracy = 0.9528, lr=0.001000\n",
      "[Train] (57, 300) loss = 0.01157, Accuracy = 0.9529, lr=0.001000\n",
      "[Train] (57, 400) loss = 0.00273, Accuracy = 0.9530, lr=0.001000\n",
      "[Train] (57, 500) loss = 0.03800, Accuracy = 0.9531, lr=0.001000\n",
      "[Train] (58, 0) loss = 0.00122, Accuracy = 0.9532, lr=0.001000\n",
      "[Train] (58, 100) loss = 0.00104, Accuracy = 0.9534, lr=0.001000\n",
      "[Train] (58, 200) loss = 0.00067, Accuracy = 0.9535, lr=0.001000\n",
      "[Train] (58, 300) loss = 0.00179, Accuracy = 0.9536, lr=0.001000\n",
      "[Train] (58, 400) loss = 0.02229, Accuracy = 0.9537, lr=0.001000\n",
      "[Train] (58, 500) loss = 0.01041, Accuracy = 0.9538, lr=0.001000\n",
      "[Train] (59, 0) loss = 0.00104, Accuracy = 0.9540, lr=0.001000\n",
      "[Train] (59, 100) loss = 0.00272, Accuracy = 0.9541, lr=0.001000\n",
      "[Train] (59, 200) loss = 0.00359, Accuracy = 0.9542, lr=0.001000\n",
      "[Train] (59, 300) loss = 0.00704, Accuracy = 0.9544, lr=0.001000\n",
      "[Train] (59, 400) loss = 0.01344, Accuracy = 0.9545, lr=0.001000\n",
      "[Train] (59, 500) loss = 0.02817, Accuracy = 0.9546, lr=0.001000\n",
      "[Train] (60, 0) loss = 0.00086, Accuracy = 0.9547, lr=0.001000\n",
      "[Train] (60, 100) loss = 0.00650, Accuracy = 0.9548, lr=0.001000\n",
      "[Train] (60, 200) loss = 0.00153, Accuracy = 0.9550, lr=0.001000\n",
      "[Train] (60, 300) loss = 0.01955, Accuracy = 0.9550, lr=0.001000\n",
      "[Train] (60, 400) loss = 0.00350, Accuracy = 0.9552, lr=0.001000\n",
      "[Train] (60, 500) loss = 0.00061, Accuracy = 0.9553, lr=0.001000\n",
      "*[Valid] Accuracy:0.8125, Precison:0.8125, Recall:0.8125, F1 Score:0.8125\n",
      "[Train] (61, 0) loss = 0.00032, Accuracy = 0.9554, lr=0.001000\n",
      "[Train] (61, 100) loss = 0.00574, Accuracy = 0.9555, lr=0.001000\n",
      "[Train] (61, 200) loss = 0.00931, Accuracy = 0.9557, lr=0.001000\n",
      "[Train] (61, 300) loss = 0.02087, Accuracy = 0.9557, lr=0.001000\n",
      "[Train] (61, 400) loss = 0.00864, Accuracy = 0.9559, lr=0.001000\n",
      "[Train] (61, 500) loss = 0.00864, Accuracy = 0.9560, lr=0.001000\n",
      "[Train] (62, 0) loss = 0.00076, Accuracy = 0.9561, lr=0.001000\n",
      "[Train] (62, 100) loss = 0.00045, Accuracy = 0.9562, lr=0.001000\n",
      "[Train] (62, 200) loss = 0.00040, Accuracy = 0.9563, lr=0.001000\n",
      "[Train] (62, 300) loss = 0.00442, Accuracy = 0.9565, lr=0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] (62, 400) loss = 0.00238, Accuracy = 0.9566, lr=0.001000\n",
      "[Train] (62, 500) loss = 0.00126, Accuracy = 0.9567, lr=0.001000\n",
      "[Train] (63, 0) loss = 0.00147, Accuracy = 0.9568, lr=0.001000\n",
      "[Train] (63, 100) loss = 0.00043, Accuracy = 0.9569, lr=0.001000\n",
      "[Train] (63, 200) loss = 0.01210, Accuracy = 0.9570, lr=0.001000\n",
      "[Train] (63, 300) loss = 0.04934, Accuracy = 0.9571, lr=0.001000\n",
      "[Train] (63, 400) loss = 0.00072, Accuracy = 0.9572, lr=0.001000\n",
      "[Train] (63, 500) loss = 0.00496, Accuracy = 0.9573, lr=0.001000\n",
      "[Train] (64, 0) loss = 0.00832, Accuracy = 0.9575, lr=0.001000\n",
      "[Train] (64, 100) loss = 0.01141, Accuracy = 0.9576, lr=0.001000\n",
      "[Train] (64, 200) loss = 0.00058, Accuracy = 0.9577, lr=0.001000\n",
      "[Train] (64, 300) loss = 0.00422, Accuracy = 0.9578, lr=0.001000\n",
      "[Train] (64, 400) loss = 0.01390, Accuracy = 0.9579, lr=0.001000\n",
      "[Train] (64, 500) loss = 0.00117, Accuracy = 0.9580, lr=0.001000\n",
      "[Train] (65, 0) loss = 0.00076, Accuracy = 0.9581, lr=0.001000\n",
      "[Train] (65, 100) loss = 0.02574, Accuracy = 0.9581, lr=0.001000\n",
      "[Train] (65, 200) loss = 0.01732, Accuracy = 0.9582, lr=0.001000\n",
      "[Train] (65, 300) loss = 0.00048, Accuracy = 0.9583, lr=0.001000\n",
      "[Train] (65, 400) loss = 0.00020, Accuracy = 0.9584, lr=0.001000\n",
      "[Train] (65, 500) loss = 0.04733, Accuracy = 0.9585, lr=0.001000\n",
      "*[Valid] Accuracy:0.8438, Precison:0.8510, Recall:0.8438, F1 Score:0.8441\n",
      "[Train] (66, 0) loss = 0.00737, Accuracy = 0.9586, lr=0.001000\n",
      "[Train] (66, 100) loss = 0.00084, Accuracy = 0.9587, lr=0.001000\n",
      "[Train] (66, 200) loss = 0.00638, Accuracy = 0.9588, lr=0.001000\n",
      "[Train] (66, 300) loss = 0.01644, Accuracy = 0.9589, lr=0.001000\n",
      "[Train] (66, 400) loss = 0.03716, Accuracy = 0.9589, lr=0.001000\n",
      "[Train] (66, 500) loss = 0.00187, Accuracy = 0.9590, lr=0.001000\n",
      "[Train] (67, 0) loss = 0.04102, Accuracy = 0.9591, lr=0.001000\n",
      "[Train] (67, 100) loss = 0.00133, Accuracy = 0.9592, lr=0.001000\n",
      "[Train] (67, 200) loss = 0.00939, Accuracy = 0.9593, lr=0.001000\n",
      "[Train] (67, 300) loss = 0.00231, Accuracy = 0.9594, lr=0.001000\n",
      "[Train] (67, 400) loss = 0.00294, Accuracy = 0.9595, lr=0.001000\n",
      "[Train] (67, 500) loss = 0.00550, Accuracy = 0.9596, lr=0.001000\n",
      "[Train] (68, 0) loss = 0.04035, Accuracy = 0.9597, lr=0.001000\n",
      "[Train] (68, 100) loss = 0.00281, Accuracy = 0.9598, lr=0.001000\n",
      "[Train] (68, 200) loss = 0.00038, Accuracy = 0.9599, lr=0.001000\n",
      "[Train] (68, 300) loss = 0.00112, Accuracy = 0.9600, lr=0.001000\n",
      "[Train] (68, 400) loss = 0.00148, Accuracy = 0.9601, lr=0.001000\n",
      "[Train] (68, 500) loss = 0.00459, Accuracy = 0.9602, lr=0.001000\n",
      "[Train] (69, 0) loss = 0.02503, Accuracy = 0.9602, lr=0.001000\n",
      "[Train] (69, 100) loss = 0.00256, Accuracy = 0.9603, lr=0.001000\n",
      "[Train] (69, 200) loss = 0.00170, Accuracy = 0.9604, lr=0.001000\n",
      "[Train] (69, 300) loss = 0.00511, Accuracy = 0.9605, lr=0.001000\n",
      "[Train] (69, 400) loss = 0.00516, Accuracy = 0.9606, lr=0.001000\n",
      "[Train] (69, 500) loss = 0.02532, Accuracy = 0.9607, lr=0.001000\n",
      "[Train] (70, 0) loss = 0.00415, Accuracy = 0.9608, lr=0.001000\n",
      "[Train] (70, 100) loss = 0.03668, Accuracy = 0.9608, lr=0.001000\n",
      "[Train] (70, 200) loss = 0.01907, Accuracy = 0.9609, lr=0.001000\n",
      "[Train] (70, 300) loss = 0.00193, Accuracy = 0.9610, lr=0.001000\n",
      "[Train] (70, 400) loss = 0.00180, Accuracy = 0.9611, lr=0.001000\n",
      "[Train] (70, 500) loss = 0.00643, Accuracy = 0.9612, lr=0.001000\n",
      "*[Valid] Accuracy:0.8125, Precison:0.8196, Recall:0.8125, F1 Score:0.8129\n",
      "[Train] (71, 0) loss = 0.04830, Accuracy = 0.9612, lr=0.001000\n",
      "[Train] (71, 100) loss = 0.00068, Accuracy = 0.9613, lr=0.001000\n",
      "[Train] (71, 200) loss = 0.00297, Accuracy = 0.9614, lr=0.001000\n",
      "[Train] (71, 300) loss = 0.00119, Accuracy = 0.9615, lr=0.001000\n",
      "[Train] (71, 400) loss = 0.03097, Accuracy = 0.9615, lr=0.001000\n",
      "[Train] (71, 500) loss = 0.06543, Accuracy = 0.9616, lr=0.001000\n",
      "[Train] (72, 0) loss = 0.02550, Accuracy = 0.9617, lr=0.001000\n",
      "[Train] (72, 100) loss = 0.00040, Accuracy = 0.9617, lr=0.001000\n",
      "[Train] (72, 200) loss = 0.00050, Accuracy = 0.9618, lr=0.001000\n",
      "[Train] (72, 300) loss = 0.00008, Accuracy = 0.9619, lr=0.001000\n",
      "[Train] (72, 400) loss = 0.09169, Accuracy = 0.9619, lr=0.001000\n",
      "[Train] (72, 500) loss = 0.00119, Accuracy = 0.9620, lr=0.001000\n",
      "[Train] (73, 0) loss = 0.00283, Accuracy = 0.9621, lr=0.001000\n",
      "[Train] (73, 100) loss = 0.00185, Accuracy = 0.9622, lr=0.001000\n",
      "[Train] (73, 200) loss = 0.00168, Accuracy = 0.9622, lr=0.001000\n",
      "[Train] (73, 300) loss = 0.00033, Accuracy = 0.9623, lr=0.001000\n",
      "[Train] (73, 400) loss = 0.01836, Accuracy = 0.9624, lr=0.001000\n",
      "[Train] (73, 500) loss = 0.01692, Accuracy = 0.9624, lr=0.001000\n",
      "[Train] (74, 0) loss = 0.00102, Accuracy = 0.9625, lr=0.001000\n",
      "[Train] (74, 100) loss = 0.00632, Accuracy = 0.9626, lr=0.001000\n",
      "[Train] (74, 200) loss = 0.00174, Accuracy = 0.9627, lr=0.001000\n",
      "[Train] (74, 300) loss = 0.00417, Accuracy = 0.9628, lr=0.001000\n",
      "[Train] (74, 400) loss = 0.00433, Accuracy = 0.9629, lr=0.001000\n",
      "[Train] (74, 500) loss = 0.00210, Accuracy = 0.9629, lr=0.001000\n",
      "[Train] (75, 0) loss = 0.01148, Accuracy = 0.9630, lr=0.001000\n",
      "[Train] (75, 100) loss = 0.00140, Accuracy = 0.9631, lr=0.001000\n",
      "[Train] (75, 200) loss = 0.00856, Accuracy = 0.9632, lr=0.001000\n",
      "[Train] (75, 300) loss = 0.00057, Accuracy = 0.9632, lr=0.001000\n",
      "[Train] (75, 400) loss = 0.00067, Accuracy = 0.9633, lr=0.001000\n",
      "[Train] (75, 500) loss = 0.01349, Accuracy = 0.9634, lr=0.001000\n",
      "*[Valid] Accuracy:0.7969, Precison:0.8007, Recall:0.7969, F1 Score:0.7970\n",
      "[Train] (76, 0) loss = 0.00035, Accuracy = 0.9634, lr=0.001000\n",
      "[Train] (76, 100) loss = 0.00213, Accuracy = 0.9635, lr=0.001000\n",
      "[Train] (76, 200) loss = 0.00019, Accuracy = 0.9636, lr=0.001000\n",
      "[Train] (76, 300) loss = 0.00277, Accuracy = 0.9637, lr=0.001000\n",
      "[Train] (76, 400) loss = 0.00131, Accuracy = 0.9638, lr=0.001000\n",
      "[Train] (76, 500) loss = 0.00069, Accuracy = 0.9639, lr=0.001000\n",
      "[Train] (77, 0) loss = 0.00067, Accuracy = 0.9639, lr=0.001000\n",
      "[Train] (77, 100) loss = 0.00088, Accuracy = 0.9640, lr=0.001000\n",
      "[Train] (77, 200) loss = 0.01220, Accuracy = 0.9641, lr=0.001000\n",
      "[Train] (77, 300) loss = 0.00044, Accuracy = 0.9642, lr=0.001000\n",
      "[Train] (77, 400) loss = 0.00961, Accuracy = 0.9642, lr=0.001000\n",
      "[Train] (77, 500) loss = 0.00017, Accuracy = 0.9643, lr=0.001000\n",
      "[Train] (78, 0) loss = 0.01006, Accuracy = 0.9644, lr=0.001000\n",
      "[Train] (78, 100) loss = 0.07561, Accuracy = 0.9644, lr=0.001000\n",
      "[Train] (78, 200) loss = 0.00149, Accuracy = 0.9645, lr=0.001000\n",
      "[Train] (78, 300) loss = 0.00177, Accuracy = 0.9646, lr=0.001000\n",
      "[Train] (78, 400) loss = 0.00167, Accuracy = 0.9646, lr=0.001000\n",
      "[Train] (78, 500) loss = 0.00515, Accuracy = 0.9647, lr=0.001000\n",
      "[Train] (79, 0) loss = 0.00020, Accuracy = 0.9648, lr=0.001000\n",
      "[Train] (79, 100) loss = 0.00657, Accuracy = 0.9649, lr=0.001000\n",
      "[Train] (79, 200) loss = 0.03257, Accuracy = 0.9649, lr=0.001000\n",
      "[Train] (79, 300) loss = 0.00320, Accuracy = 0.9650, lr=0.001000\n",
      "[Train] (79, 400) loss = 0.01416, Accuracy = 0.9650, lr=0.001000\n",
      "[Train] (79, 500) loss = 0.00802, Accuracy = 0.9651, lr=0.001000\n",
      "[Train] (80, 0) loss = 0.00647, Accuracy = 0.9652, lr=0.001000\n",
      "[Train] (80, 100) loss = 0.02262, Accuracy = 0.9652, lr=0.001000\n",
      "[Train] (80, 200) loss = 0.00089, Accuracy = 0.9653, lr=0.001000\n",
      "[Train] (80, 300) loss = 0.00135, Accuracy = 0.9654, lr=0.001000\n",
      "[Train] (80, 400) loss = 0.00542, Accuracy = 0.9654, lr=0.001000\n",
      "[Train] (80, 500) loss = 0.00130, Accuracy = 0.9655, lr=0.001000\n",
      "*[Valid] Accuracy:0.8438, Precison:0.8460, Recall:0.8438, F1 Score:0.8441\n",
      "[Train] (81, 0) loss = 0.00024, Accuracy = 0.9656, lr=0.001000\n",
      "[Train] (81, 100) loss = 0.00107, Accuracy = 0.9656, lr=0.001000\n",
      "[Train] (81, 200) loss = 0.00463, Accuracy = 0.9657, lr=0.001000\n",
      "[Train] (81, 300) loss = 0.00041, Accuracy = 0.9658, lr=0.001000\n",
      "[Train] (81, 400) loss = 0.02056, Accuracy = 0.9658, lr=0.001000\n",
      "[Train] (81, 500) loss = 0.04541, Accuracy = 0.9659, lr=0.001000\n",
      "[Train] (82, 0) loss = 0.00598, Accuracy = 0.9659, lr=0.001000\n",
      "[Train] (82, 100) loss = 0.00049, Accuracy = 0.9660, lr=0.001000\n",
      "[Train] (82, 200) loss = 0.01384, Accuracy = 0.9661, lr=0.001000\n",
      "[Train] (82, 300) loss = 0.00011, Accuracy = 0.9661, lr=0.001000\n",
      "[Train] (82, 400) loss = 0.02429, Accuracy = 0.9662, lr=0.001000\n",
      "[Train] (82, 500) loss = 0.03785, Accuracy = 0.9662, lr=0.001000\n",
      "[Train] (83, 0) loss = 0.00665, Accuracy = 0.9662, lr=0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] (83, 100) loss = 0.01826, Accuracy = 0.9663, lr=0.001000\n",
      "[Train] (83, 200) loss = 0.00027, Accuracy = 0.9664, lr=0.001000\n",
      "[Train] (83, 300) loss = 0.00234, Accuracy = 0.9664, lr=0.001000\n",
      "[Train] (83, 400) loss = 0.00133, Accuracy = 0.9665, lr=0.001000\n",
      "[Train] (83, 500) loss = 0.02004, Accuracy = 0.9665, lr=0.001000\n",
      "[Train] (84, 0) loss = 0.00095, Accuracy = 0.9666, lr=0.001000\n",
      "[Train] (84, 100) loss = 0.00011, Accuracy = 0.9667, lr=0.001000\n",
      "[Train] (84, 200) loss = 0.00019, Accuracy = 0.9667, lr=0.001000\n",
      "[Train] (84, 300) loss = 0.00090, Accuracy = 0.9668, lr=0.001000\n",
      "[Train] (84, 400) loss = 0.00090, Accuracy = 0.9669, lr=0.001000\n",
      "[Train] (84, 500) loss = 0.00369, Accuracy = 0.9669, lr=0.001000\n",
      "[Train] (85, 0) loss = 0.00260, Accuracy = 0.9670, lr=0.001000\n",
      "[Train] (85, 100) loss = 0.01098, Accuracy = 0.9671, lr=0.001000\n",
      "[Train] (85, 200) loss = 0.00115, Accuracy = 0.9671, lr=0.001000\n",
      "[Train] (85, 300) loss = 0.07804, Accuracy = 0.9671, lr=0.001000\n",
      "[Train] (85, 400) loss = 0.00018, Accuracy = 0.9672, lr=0.001000\n",
      "[Train] (85, 500) loss = 0.00140, Accuracy = 0.9672, lr=0.001000\n",
      "*[Valid] Accuracy:0.8125, Precison:0.8125, Recall:0.8125, F1 Score:0.8125\n",
      "[Train] (86, 0) loss = 0.00035, Accuracy = 0.9673, lr=0.001000\n",
      "[Train] (86, 100) loss = 0.00204, Accuracy = 0.9674, lr=0.001000\n",
      "[Train] (86, 200) loss = 0.00065, Accuracy = 0.9674, lr=0.001000\n",
      "[Train] (86, 300) loss = 0.00571, Accuracy = 0.9675, lr=0.001000\n",
      "[Train] (86, 400) loss = 0.00132, Accuracy = 0.9676, lr=0.001000\n",
      "[Train] (86, 500) loss = 0.00008, Accuracy = 0.9676, lr=0.001000\n",
      "[Train] (87, 0) loss = 0.00262, Accuracy = 0.9677, lr=0.001000\n",
      "[Train] (87, 100) loss = 0.00737, Accuracy = 0.9678, lr=0.001000\n",
      "[Train] (87, 200) loss = 0.00600, Accuracy = 0.9678, lr=0.001000\n",
      "[Train] (87, 300) loss = 0.00024, Accuracy = 0.9679, lr=0.001000\n",
      "[Train] (87, 400) loss = 0.00346, Accuracy = 0.9679, lr=0.001000\n",
      "[Train] (87, 500) loss = 0.01158, Accuracy = 0.9680, lr=0.001000\n",
      "[Train] (88, 0) loss = 0.00902, Accuracy = 0.9681, lr=0.001000\n",
      "[Train] (88, 100) loss = 0.00105, Accuracy = 0.9681, lr=0.001000\n",
      "[Train] (88, 200) loss = 0.00039, Accuracy = 0.9682, lr=0.001000\n",
      "[Train] (88, 300) loss = 0.00082, Accuracy = 0.9682, lr=0.001000\n",
      "[Train] (88, 400) loss = 0.00109, Accuracy = 0.9683, lr=0.001000\n",
      "[Train] (88, 500) loss = 0.02318, Accuracy = 0.9683, lr=0.001000\n",
      "[Train] (89, 0) loss = 0.01309, Accuracy = 0.9684, lr=0.001000\n",
      "[Train] (89, 100) loss = 0.00050, Accuracy = 0.9684, lr=0.001000\n",
      "[Train] (89, 200) loss = 0.00098, Accuracy = 0.9685, lr=0.001000\n",
      "[Train] (89, 300) loss = 0.00007, Accuracy = 0.9685, lr=0.001000\n",
      "[Train] (89, 400) loss = 0.02642, Accuracy = 0.9686, lr=0.001000\n",
      "[Train] (89, 500) loss = 0.00100, Accuracy = 0.9686, lr=0.001000\n",
      "[Train] (90, 0) loss = 0.00045, Accuracy = 0.9687, lr=0.001000\n",
      "[Train] (90, 100) loss = 0.00027, Accuracy = 0.9688, lr=0.001000\n",
      "[Train] (90, 200) loss = 0.01832, Accuracy = 0.9688, lr=0.001000\n",
      "[Train] (90, 300) loss = 0.02316, Accuracy = 0.9688, lr=0.001000\n",
      "[Train] (90, 400) loss = 0.02041, Accuracy = 0.9688, lr=0.001000\n",
      "[Train] (90, 500) loss = 0.00068, Accuracy = 0.9689, lr=0.001000\n",
      "*[Valid] Accuracy:0.8594, Precison:0.8597, Recall:0.8594, F1 Score:0.8593\n",
      "[Train] (91, 0) loss = 0.00101, Accuracy = 0.9690, lr=0.001000\n",
      "[Train] (91, 100) loss = 0.00042, Accuracy = 0.9690, lr=0.001000\n",
      "[Train] (91, 200) loss = 0.00197, Accuracy = 0.9691, lr=0.001000\n",
      "[Train] (91, 300) loss = 0.00008, Accuracy = 0.9691, lr=0.001000\n",
      "[Train] (91, 400) loss = 0.00491, Accuracy = 0.9692, lr=0.001000\n",
      "[Train] (91, 500) loss = 0.00201, Accuracy = 0.9692, lr=0.001000\n",
      "[Train] (92, 0) loss = 0.14436, Accuracy = 0.9692, lr=0.001000\n",
      "[Train] (92, 100) loss = 0.00832, Accuracy = 0.9693, lr=0.001000\n",
      "[Train] (92, 200) loss = 0.00095, Accuracy = 0.9693, lr=0.001000\n",
      "[Train] (92, 300) loss = 0.00255, Accuracy = 0.9694, lr=0.001000\n",
      "[Train] (92, 400) loss = 0.00631, Accuracy = 0.9695, lr=0.001000\n",
      "[Train] (92, 500) loss = 0.00472, Accuracy = 0.9695, lr=0.001000\n",
      "[Train] (93, 0) loss = 0.00183, Accuracy = 0.9696, lr=0.001000\n",
      "[Train] (93, 100) loss = 0.00037, Accuracy = 0.9696, lr=0.001000\n",
      "[Train] (93, 200) loss = 0.01879, Accuracy = 0.9697, lr=0.001000\n",
      "[Train] (93, 300) loss = 0.00044, Accuracy = 0.9697, lr=0.001000\n",
      "[Train] (93, 400) loss = 0.00021, Accuracy = 0.9698, lr=0.001000\n",
      "[Train] (93, 500) loss = 0.00038, Accuracy = 0.9698, lr=0.001000\n",
      "[Train] (94, 0) loss = 0.00029, Accuracy = 0.9699, lr=0.001000\n",
      "[Train] (94, 100) loss = 0.00026, Accuracy = 0.9699, lr=0.001000\n",
      "[Train] (94, 200) loss = 0.00042, Accuracy = 0.9700, lr=0.001000\n",
      "[Train] (94, 300) loss = 0.00032, Accuracy = 0.9700, lr=0.001000\n",
      "[Train] (94, 400) loss = 0.02202, Accuracy = 0.9701, lr=0.001000\n",
      "[Train] (94, 500) loss = 0.00056, Accuracy = 0.9701, lr=0.001000\n",
      "[Train] (95, 0) loss = 0.00128, Accuracy = 0.9702, lr=0.001000\n",
      "[Train] (95, 100) loss = 0.00056, Accuracy = 0.9702, lr=0.001000\n",
      "[Train] (95, 200) loss = 0.02361, Accuracy = 0.9702, lr=0.001000\n",
      "[Train] (95, 300) loss = 0.00020, Accuracy = 0.9703, lr=0.001000\n",
      "[Train] (95, 400) loss = 0.01211, Accuracy = 0.9703, lr=0.001000\n",
      "[Train] (95, 500) loss = 0.00064, Accuracy = 0.9704, lr=0.001000\n",
      "*[Valid] Accuracy:0.7969, Precison:0.8101, Recall:0.7969, F1 Score:0.7986\n",
      "[Train] (96, 0) loss = 0.00121, Accuracy = 0.9704, lr=0.001000\n",
      "[Train] (96, 100) loss = 0.00026, Accuracy = 0.9705, lr=0.001000\n",
      "[Train] (96, 200) loss = 0.06847, Accuracy = 0.9705, lr=0.001000\n",
      "[Train] (96, 300) loss = 0.01420, Accuracy = 0.9705, lr=0.001000\n",
      "[Train] (96, 400) loss = 0.00133, Accuracy = 0.9706, lr=0.001000\n",
      "[Train] (96, 500) loss = 0.00074, Accuracy = 0.9706, lr=0.001000\n",
      "[Train] (97, 0) loss = 0.00033, Accuracy = 0.9707, lr=0.001000\n",
      "[Train] (97, 100) loss = 0.00021, Accuracy = 0.9708, lr=0.001000\n",
      "[Train] (97, 200) loss = 0.00103, Accuracy = 0.9708, lr=0.001000\n",
      "[Train] (97, 300) loss = 0.00111, Accuracy = 0.9709, lr=0.001000\n",
      "[Train] (97, 400) loss = 0.04748, Accuracy = 0.9709, lr=0.001000\n",
      "[Train] (97, 500) loss = 0.00141, Accuracy = 0.9709, lr=0.001000\n",
      "[Train] (98, 0) loss = 0.00050, Accuracy = 0.9710, lr=0.001000\n",
      "[Train] (98, 100) loss = 0.03784, Accuracy = 0.9710, lr=0.001000\n",
      "[Train] (98, 200) loss = 0.00119, Accuracy = 0.9710, lr=0.001000\n",
      "[Train] (98, 300) loss = 0.07375, Accuracy = 0.9711, lr=0.001000\n",
      "[Train] (98, 400) loss = 0.02127, Accuracy = 0.9711, lr=0.001000\n",
      "[Train] (98, 500) loss = 0.00015, Accuracy = 0.9711, lr=0.001000\n",
      "[Train] (99, 0) loss = 0.00469, Accuracy = 0.9712, lr=0.001000\n",
      "[Train] (99, 100) loss = 0.01730, Accuracy = 0.9712, lr=0.001000\n",
      "[Train] (99, 200) loss = 0.00887, Accuracy = 0.9713, lr=0.001000\n",
      "[Train] (99, 300) loss = 0.00153, Accuracy = 0.9713, lr=0.001000\n",
      "[Train] (99, 400) loss = 0.05433, Accuracy = 0.9714, lr=0.001000\n",
      "[Train] (99, 500) loss = 0.00046, Accuracy = 0.9714, lr=0.001000\n",
      "[Train] (100, 0) loss = 0.00505, Accuracy = 0.9715, lr=0.001000\n",
      "[Train] (100, 100) loss = 0.00020, Accuracy = 0.9715, lr=0.001000\n",
      "[Train] (100, 200) loss = 0.00033, Accuracy = 0.9716, lr=0.001000\n",
      "[Train] (100, 300) loss = 0.00864, Accuracy = 0.9716, lr=0.001000\n",
      "[Train] (100, 400) loss = 0.00021, Accuracy = 0.9716, lr=0.001000\n",
      "[Train] (100, 500) loss = 0.00319, Accuracy = 0.9717, lr=0.001000\n",
      "*[Valid] Accuracy:0.8438, Precison:0.8454, Recall:0.8438, F1 Score:0.8438\n",
      "Time : 313.9409439563751[s]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "train_acc = []\n",
    "tmp_acc = 0\n",
    "loss_arr = []\n",
    "\n",
    "print(\"*Train Start!!*\")\n",
    "if torch.cuda.device_count() == True:\n",
    "    print(\"epoch : {}, learing rate : {}, device : {}\".format(num_epoch, lr, torch.cuda.get_device_name(0)))\n",
    "else:\n",
    "    print(\"epoch : {}, learing rate : {}, device : {}\".format(num_epoch, lr, device))\n",
    "print(\"Model : {}\".format(model._get_name()))\n",
    "print(\"Loss function : {}\".format(loss_function._get_name()))\n",
    "print(\"Optimizer : {}\".format(str(optimizer).replace(\"\\n\", \" \").replace(\"     \", \", \")))\n",
    "print(\"*\"*100)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "tmp_acc = 0\n",
    "train_acc = []\n",
    "loss_arr = []\n",
    "val_view_acc = []\n",
    "start = time.time()  # 시작 시간 저장\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    epoch = epoch + 1\n",
    "    for train_iter, (train_x, train_y_true) in enumerate(trainloader):\n",
    "        model.train()  # Train mode\n",
    "        model.zero_grad()  # model zero initialize\n",
    "        optimizer.zero_grad()  # optimizer zero initialize\n",
    "        \n",
    "        train_x, train_y_true = train_x.to(device), train_y_true.to(device)  # device(gpu)\n",
    "        train_y_pred = model.forward(train_x)  # forward\n",
    "\n",
    "        loss = loss_function(train_y_pred, train_y_true)  # loss function\n",
    "        loss.backward()  # backward\n",
    "        optimizer.step()  # optimizer\n",
    "        _, pred_index = torch.max(train_y_pred, 1)\n",
    "    \n",
    "        if train_iter % view_train_iter == 0:\n",
    "            loss_arr.append(loss.item())\n",
    "            total += train_y_true.size(0)  # y.size(0)\n",
    "            correct += (pred_index == train_y_true).sum().float()  # correct\n",
    "            tmp_acc = correct / total  # accuracy\n",
    "            train_acc.append(tmp_acc.tolist())\n",
    "            print(\"[Train] ({}, {}) loss = {:.5f}, Accuracy = {:.4f}, lr={:.6f}\".format(epoch, train_iter, loss.item(), tmp_acc, optimizer.param_groups[0]['lr']))\n",
    "    # validation \n",
    "    if epoch % view_val_iter == 0: \n",
    "        val_actual_tmp, val_pred_tmp = [], []\n",
    "        for val_iter, (val_x, val_y_true) in enumerate(validationloader):\n",
    "            model.eval()\n",
    "            val_x, val_y_true = val_x.to(device), val_y_true.to(device)  # device(gpu)\n",
    "            val_y_pred = model.forward(val_x)  # forward\n",
    "            _, val_pred_index = torch.max(val_y_pred, 1)\n",
    "            \n",
    "            val_pred_index_cpu = val_pred_index.cpu().detach().numpy()\n",
    "            val_y_true_cpu = val_y_true.cpu().detach().numpy()\n",
    "            \n",
    "            val_actual_tmp.append(val_pred_index_cpu.tolist())\n",
    "            val_pred_tmp.append(val_y_true_cpu.tolist())\n",
    "            \n",
    "        val_acc, val_precision, val_recall, val_f1 = get_clf_eval(val_actual_tmp[1], val_pred_tmp[1])\n",
    "        val_view_acc.append(val_acc)\n",
    "        print(\"*[Valid] Accuracy:{:.4f}, Precison:{:.4f}, Recall:{:.4f}, F1 Score:{:.4f}\".format(\n",
    "             val_acc, val_precision, val_recall, val_f1))\n",
    "print(\"Time : \", time.time()-start,'[s]',sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:34:18.633164Z",
     "start_time": "2022-02-01T13:34:18.436172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./[plot] CNN_LSTM_layer2.pdf\n"
     ]
    }
   ],
   "source": [
    "f = plt.figure(figsize=[8, 5])\n",
    "f.set_facecolor(\"white\")\n",
    "\n",
    "plt.style.use(['default'])\n",
    "plt.plot(loss_arr)\n",
    "plt.plot(train_acc)\n",
    "\n",
    "\n",
    "plt.legend(['Loss', 'Accuracy'])\n",
    "plt.ylim((0.0, 1.05))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(\"./\"+\"[plot] \"+model._get_name()+\"_\"+'layer'+str(num_layers)+\".pdf\")\n",
    "f.savefig(\"./\"+\"[plot] \"+model._get_name()+\"_\"+'layer'+str(num_layers)+\".pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:34:40.302411Z",
     "start_time": "2022-02-01T13:34:40.114803Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Accuracy : 0.8424, Precision : 0.8468, Recall : 0.8424, F1 Score : 0.8422\n",
      "[Test] Model Performance : 0.84243\n",
      "Time : 0.1676795482635498[s]\n"
     ]
    }
   ],
   "source": [
    "# for confusion matrix\n",
    "\n",
    "test_pred_acc = []  \n",
    "test_actual_acc = []  \n",
    "start = time.time()  # 시작 시간 저장\n",
    "device = 'cuda:0'\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_acc_tmp, test_precision_tmp, test_recall_tmp, test_f1_tmp = [], [], [], []\n",
    "    for test_iter, (test_x, test_y_true) in enumerate(testloader):\n",
    "        test_x, test_y_true = test_x.to(device), test_y_true.to(device)\n",
    "        test_y_pred = model.forward(test_x)  # forward\n",
    "        \n",
    "        _, test_pred_index = torch.max(test_y_pred, 1)\n",
    "\n",
    "        test_pred_index_cpu = test_pred_index.cpu().detach().numpy()\n",
    "        test_y_true_cpu = test_y_true.cpu().detach().numpy()\n",
    "        \n",
    "        test_pred_acc.append(test_pred_index_cpu)\n",
    "        test_actual_acc.append(test_y_true_cpu)\n",
    "            \n",
    "        test_acc, test_precision, test_recall, test_f1 = get_clf_eval(test_y_true_cpu, test_pred_index_cpu)\n",
    "\n",
    "        test_acc_tmp.append(test_acc), test_precision_tmp.append(test_precision), test_recall_tmp.append(test_recall), test_f1_tmp.append(test_f1)\n",
    "    test_acc_mean = sum(test_acc_tmp, 0.0)/len(test_acc_tmp)\n",
    "    test_precision_mean = sum(test_precision_tmp, 0.0)/len(test_precision_tmp)\n",
    "    test_recall_mean = sum(test_recall_tmp, 0.0)/len(test_recall_tmp)\n",
    "    test_f1_mean = sum(test_f1_tmp, 0.0)/len(test_f1_tmp)\n",
    "    print(\"[Test] Accuracy : {:.4f}, Precision : {:.4f}, Recall : {:.4f}, F1 Score : {:.4f}\".format(\n",
    "         test_acc_mean, test_precision_mean, test_recall_mean, test_f1_mean))\n",
    "    print(\"[Test] Model Performance : {:.5f}\".format(test_acc_mean))\n",
    "print(\"Time : \", time.time()-start,'[s]',sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:34:42.770045Z",
     "start_time": "2022-02-01T13:34:42.763035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yoon\\Documents\\JupyterNotebook_Server\\UWB\\model\\[CNN_LSTM](epoch-100)-(init_lr-0.001)-(batch-64)-(acc-84).pt\n"
     ]
    }
   ],
   "source": [
    "epoch_str = str(epoch)\n",
    "lr_str = str(lr)\n",
    "batch_str= str(batch_size)\n",
    "acc_str= str(int(test_acc_mean*100))\n",
    "\n",
    "model_name = \"[\"+model._get_name()+\"]\"+\"(epoch-\"+epoch_str+\")-\"+\"(init_lr-\"+lr_str+\")-\"+\"(batch-\"+batch_str+\")-\"+\"(acc-\"+acc_str+\").pt\"\n",
    "save_path = os.path.join(path, dir_ , model_name)\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:34:43.981273Z",
     "start_time": "2022-02-01T13:34:43.965269Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1d_layer.0.weight \t torch.Size([10, 1, 4])\n",
      "conv1d_layer.0.bias \t torch.Size([10])\n",
      "conv1d_layer.2.weight \t torch.Size([20, 10, 5])\n",
      "conv1d_layer.2.bias \t torch.Size([20])\n",
      "lstm.weight_ih_l0 \t torch.Size([128, 504])\n",
      "lstm.weight_hh_l0 \t torch.Size([128, 32])\n",
      "lstm.weight_ih_l0_reverse \t torch.Size([128, 504])\n",
      "lstm.weight_hh_l0_reverse \t torch.Size([128, 32])\n",
      "lstm.weight_ih_l1 \t torch.Size([128, 64])\n",
      "lstm.weight_hh_l1 \t torch.Size([128, 32])\n",
      "lstm.weight_ih_l1_reverse \t torch.Size([128, 64])\n",
      "lstm.weight_hh_l1_reverse \t torch.Size([128, 32])\n",
      "bn.weight \t torch.Size([64])\n",
      "bn.bias \t torch.Size([64])\n",
      "bn.running_mean \t torch.Size([64])\n",
      "bn.running_var \t torch.Size([64])\n",
      "bn.num_batches_tracked \t torch.Size([])\n",
      "fc_layer.weight \t torch.Size([128, 64])\n",
      "fc_layer.bias \t torch.Size([128])\n",
      "fc_layer_class.weight \t torch.Size([2, 128])\n",
      "fc_layer_class.bias \t torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:34:46.333925Z",
     "start_time": "2022-02-01T13:34:46.317924Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save({'epoch' : epoch,\n",
    "            'model_state_dict' : model.state_dict(),\n",
    "            'optimizer_state_dict' : optimizer.state_dict(),\n",
    "            'loss' : loss\n",
    "           }, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
